helpers.py                    :     6:  if TYPE_CHECKING:  # TODO: remove this and import TypeGuard from typing once minimum python supported version is 3.10
helpers.py                    :    10:  T = TypeVar("T")
helpers.py                    :    11:  U = TypeVar("U")
helpers.py                    :    16:  OSX = platform.system() == "Darwin"
helpers.py                    :    17:  CI = os.getenv("CI", "") != ""

helpers.py                    :    81:    class Context(contextlib.ContextDecorator):
helpers.py                    :    82:      stack: ClassVar[List[dict[str, int]]] = [{}]

helpers.py                    :    91:    class ContextVar:
helpers.py                    :    92:      _cache: ClassVar[Dict[str, ContextVar]] = {}
helpers.py                    :    93:      value: int
helpers.py                    :    94:      key: str

helpers.py                    :   105:  DEBUG, IMAGE, BEAM, NOOPT, JIT = ContextVar("DEBUG", 0), ContextVar("IMAGE", 0), ContextVar("BEAM", 0), ContextVar("NOOPT", 0), ContextVar("JIT", 1)

helpers.py                    :    91:    class ContextVar:
helpers.py                    :    95:      def __new__(cls, key, default_value):
helpers.py                    :    96:        if key in ContextVar._cache: return ContextVar._cache[key]
helpers.py                    :    97:        instance = ContextVar._cache[key] = super().__new__(cls)
helpers.py                    :    98:        instance.value, instance.key = getenv(key, default_value), key

helpers.py                    :    91:    class ContextVar:
helpers.py                    :    95:      def __new__(cls, key, default_value):
helpers.py                    :    99:        return instance

helpers.py                    :   106:  WINO, THREEFRY, CAPTURING, TRACEMETA = ContextVar("WINO", 0), ContextVar("THREEFRY", 0), ContextVar("CAPTURING", 1), ContextVar("TRACEMETA", 1)
helpers.py                    :   107:  GRAPH, GRAPHPATH, SAVE_SCHEDULE, RING = ContextVar("GRAPH", 0), getenv("GRAPHPATH", "/tmp/net"), ContextVar("SAVE_SCHEDULE", 0), ContextVar("RING", 1)
helpers.py                    :   108:  MULTIOUTPUT, PROFILE, TRANSCENDENTAL = ContextVar("MULTIOUTPUT", 1), ContextVar("PROFILE", 0), ContextVar("TRANSCENDENTAL", 1)
helpers.py                    :   109:  USE_TC, TC_OPT = ContextVar("TC", 1), ContextVar("TC_OPT", 0)
helpers.py                    :   110:  FUSE_AS_ONE_KERNEL = ContextVar("FUSE_AS_ONE_KERNEL", 0)

helpers.py                    :   113:    @dataclass(frozen=True)
helpers.py                    :   113:    class Metadata:
helpers.py                    :   114:      name: str
helpers.py                    :   115:      caller: str
helpers.py                    :   116:      backward: bool = False

helpers.py                    :   120:  _METADATA: contextvars.ContextVar[Optional[Metadata]] = contextvars.ContextVar("_METADATA", default=None)

helpers.py                    :   124:    class GlobalCounters:
helpers.py                    :   125:      global_ops: ClassVar[int] = 0
helpers.py                    :   126:      global_mem: ClassVar[int] = 0
helpers.py                    :   127:      time_sum_s: ClassVar[float] = 0.0
helpers.py                    :   128:      kernel_count: ClassVar[int] = 0
helpers.py                    :   129:      mem_used: ClassVar[int] = 0   # NOTE: this is not reset

helpers.py                    :   161:    class ProfileLogger:
helpers.py                    :   162:      writers: int = 0
helpers.py                    :   163:      mjson: List[Dict] = []
helpers.py                    :   164:      actors: Dict[str, int] = {}
helpers.py                    :   165:      subactors: Dict[Tuple[str, str], int] = {}
helpers.py                    :   166:      path = getenv("PROFILE_OUTPUT_FILE", temp("tinygrad_profile.json"))

helpers.py                    :   191:  _cache_dir: str = getenv("XDG_CACHE_HOME", os.path.expanduser("~/Library/Caches" if OSX else "~/.cache"))
helpers.py                    :   192:  CACHEDB: str = getenv("CACHEDB", os.path.abspath(os.path.join(_cache_dir, "tinygrad", "cache.db")))
helpers.py                    :   193:  CACHELEVEL = getenv("CACHELEVEL", 2)
helpers.py                    :   195:  VERSION = 16
helpers.py                    :   196:  _db_connection = None
helpers.py                    :   223:  _db_tables = set()
dtype.py                      :     6:  ConstType = Union[float, int, bool]

dtype.py                      :     9:    @dataclass(frozen=True, order=True)
dtype.py                      :     9:    class DType:
dtype.py                      :    10:      priority: int  # this determines when things get upcasted
dtype.py                      :    11:      itemsize: int
dtype.py                      :    12:      name: str
dtype.py                      :    13:      fmt: Optional[str]
dtype.py                      :    14:      count: int

dtype.py                      :    23:    # dependent typing?
dtype.py                      :    23:    @dataclass(frozen=True, repr=False)
dtype.py                      :    23:    class ImageDType(DType):
dtype.py                      :    24:      shape: Tuple[int, ...]   # arbitrary arg for the dtype, used in image for the shape
dtype.py                      :    25:      base: DType

dtype.py                      :    38:    class dtypes:
dtype.py                      :    65:      bigint: Final[DType] = DType(-1, 0, "bigint", None, 1)   # arbitrary precision integer
dtype.py                      :    66:      bool: Final[DType] = DType(0, 1, "bool", '?', 1)
dtype.py                      :    67:      int8: Final[DType] = DType(1, 1, "char", 'b', 1)
dtype.py                      :    68:      uint8: Final[DType] = DType(2, 1, "unsigned char", 'B', 1)
dtype.py                      :    69:      int16: Final[DType] = DType(3, 2, "short", 'h', 1)
dtype.py                      :    70:      uint16: Final[DType] = DType(4, 2, "unsigned short", 'H', 1)
dtype.py                      :    71:      int32: Final[DType] = DType(5, 4, "int", 'i', 1)
dtype.py                      :    72:      uint32: Final[DType] = DType(6, 4, "unsigned int", 'I', 1)
dtype.py                      :    73:      int64: Final[DType] = DType(7, 8, "long", 'l', 1)
dtype.py                      :    74:      uint64: Final[DType] = DType(8, 8, "unsigned long", 'L', 1)
dtype.py                      :    75:      float16: Final[DType] = DType(9, 2, "half", 'e', 1)
dtype.py                      :    77:      bfloat16: Final[DType] = DType(10, 2, "__bf16", None, 1)
dtype.py                      :    78:      float32: Final[DType] = DType(11, 4, "float", 'f', 1)
dtype.py                      :    79:      float64: Final[DType] = DType(12, 8, "double", 'd', 1)
dtype.py                      :    82:      half = float16; float = float32; double = float64 # noqa: E702
dtype.py                      :    83:      uchar = uint8; ushort = uint16; uint = uint32; ulong = uint64 # noqa: E702
dtype.py                      :    84:      char = int8; short = int16; int = int32; long = int64 # noqa: E702
dtype.py                      :    92:      default_float: ClassVar[DType] = float32
dtype.py                      :    93:      default_int: ClassVar[DType] = int32

dtype.py                      :    95:  if (env_default_float := getenv("DEFAULT_FLOAT", "")):
dtype.py                      :   101:  promo_lattice = { dtypes.bool: [dtypes.int8, dtypes.uint8], dtypes.int8: [dtypes.int16], dtypes.int16: [dtypes.int32], dtypes.int32: [dtypes.int64],
dtype.py                      :   101:    dtypes.int64: [dtypes.float16, dtypes.bfloat16], dtypes.uint8: [dtypes.int16, dtypes.uint16], dtypes.uint16: [dtypes.int32, dtypes.uint32],
dtype.py                      :   101:    dtypes.uint32: [dtypes.int64, dtypes.uint64], dtypes.uint64: [dtypes.float16, dtypes.bfloat16],
dtype.py                      :   101:    dtypes.float16: [dtypes.float32], dtypes.bfloat16: [dtypes.float32], dtypes.float32: [dtypes.float64], }
dtype.py                      :   115:  DTYPES_DICT = {k: v for k, v in dtypes.__dict__.items() if not (k.startswith(('__', 'default', 'bigint')) or v.__class__ is staticmethod)}
dtype.py                      :   116:  INVERSE_DTYPES_DICT = {v.name:k for k,v in DTYPES_DICT.items()}
dtype.py                      :   117:  INVERSE_DTYPES_DICT['bigint'] = 'bigint'

shape/symbolic.py             :    10:    class Node:
shape/symbolic.py             :    11:      b: Union[Node, int]
shape/symbolic.py             :    12:      min: int
shape/symbolic.py             :    13:      max: sint

shape/symbolic.py             :   309:  sint = Union[int, Variable, MulNode, SumNode]
shape/symbolic.py             :   318:    Variable: lambda self,ops,ctx: f"{self.expr}[{self.min}-{self.max}{'='+str(self.val) if self._val is not None else ''}]" if ctx == "DEBUG" \
shape/symbolic.py             :   318:      else (f"Variable('{self.expr}', {self.min}, {self.max})"+(f".bind({self.val})" if self._val is not None else '') if ctx == "REPR" \
shape/symbolic.py             :   318:      else f"{self.expr}"),
shape/symbolic.py             :   321:    NumNode: lambda self,ops,ctx: f"NumNode({self.b})" if ctx == "REPR" else f"{self.b}",
shape/symbolic.py             :   322:    MulNode: render_mulnode,
shape/symbolic.py             :   323:    DivNode: lambda self,ops,ctx: f"({self.a.render(ops,ctx)}//{self.b})",
shape/symbolic.py             :   324:    ModNode: lambda self,ops,ctx: f"({self.a.render(ops,ctx)}%{self.b})",
shape/symbolic.py             :   325:    LtNode: lambda self,ops,ctx: f"({self.a.render(ops,ctx)}<{sym_render(self.b,ops,ctx)})",
shape/symbolic.py             :   326:    SumNode: lambda self,ops,ctx: f"({'+'.join(sorted([x.render(ops,ctx) for x in self.nodes]))})",
shape/symbolic.py             :   327:    AndNode: lambda self,ops,ctx: f"({' and '.join(sorted([x.render(ops,ctx) for x in self.nodes]))})",
shape/symbolic.py             :   317:  render_python: Dict[Type, Callable[..., str]] = {
shape/symbolic.py             :   317:    Variable: lambda self,ops,ctx: f"{self.expr}[{self.min}-{self.max}{'='+str(self.val) if self._val is not None else ''}]" if ctx == "DEBUG" \
shape/symbolic.py             :   317:      else (f"Variable('{self.expr}', {self.min}, {self.max})"+(f".bind({self.val})" if self._val is not None else '') if ctx == "REPR" \
shape/symbolic.py             :   317:      else f"{self.expr}"),
shape/symbolic.py             :   317:    NumNode: lambda self,ops,ctx: f"NumNode({self.b})" if ctx == "REPR" else f"{self.b}",
shape/symbolic.py             :   317:    MulNode: render_mulnode,
shape/symbolic.py             :   317:    DivNode: lambda self,ops,ctx: f"({self.a.render(ops,ctx)}//{self.b})",
shape/symbolic.py             :   317:    ModNode: lambda self,ops,ctx: f"({self.a.render(ops,ctx)}%{self.b})",
shape/symbolic.py             :   317:    LtNode: lambda self,ops,ctx: f"({self.a.render(ops,ctx)}<{sym_render(self.b,ops,ctx)})",
shape/symbolic.py             :   317:    SumNode: lambda self,ops,ctx: f"({'+'.join(sorted([x.render(ops,ctx) for x in self.nodes]))})",
shape/symbolic.py             :   317:    AndNode: lambda self,ops,ctx: f"({' and '.join(sorted([x.render(ops,ctx) for x in self.nodes]))})",
shape/symbolic.py             :   317:  }

shape/view.py                 :    85:    @dataclass(frozen=True)
shape/view.py                 :    85:    class View:
shape/view.py                 :    86:      shape:Tuple[sint, ...]
shape/view.py                 :    87:      strides:Tuple[sint, ...]
shape/view.py                 :    88:      offset:sint
shape/view.py                 :    89:      mask:Optional[Tuple[Tuple[sint, sint], ...]]
shape/view.py                 :    90:      contiguous:bool

shape/shapetracker.py         :    10:    @dataclass(frozen=True)
shape/shapetracker.py         :    10:    class ShapeTracker:
shape/shapetracker.py         :    11:      views: Tuple[View, ...]

ops.py                        :    15:    # these are the llops your accelerator must implement, along with toCpu
ops.py                        :    15:    # the Enum class doesn't work with mypy, this is static. sorry it's ugly
ops.py                        :    15:    # NOTE: MOD, CMPLT don't have to be implemented on vectors, just scalars
ops.py                        :    15:    # NOTE: many GPUs don't have DIV, but UnaryOps.RECIP doesn't work for integer division
ops.py                        :    15:    class UnaryOps(Enum):
ops.py                        :    16:      """A -> A (elementwise)"""
ops.py                        :    17:      EXP2 = auto(); LOG2 = auto(); CAST = auto(); BITCAST = auto(); SIN = auto(); SQRT = auto(); NEG = auto(); RECIP = auto() # noqa: E702

ops.py                        :    18:    class BinaryOps(Enum):
ops.py                        :    19:      """A + A -> A (elementwise)"""
ops.py                        :    20:      ADD = auto(); MUL = auto(); IDIV = auto(); MAX = auto(); MOD = auto(); CMPLT = auto(); CMPNE = auto(); XOR = auto() # noqa: E702
ops.py                        :    21:      SHL = auto(); SHR = auto(); OR = auto(); AND = auto(); THREEFRY = auto() # noqa: E702

ops.py                        :    22:    class TernaryOps(Enum):
ops.py                        :    23:      """A + A + A -> A (elementwise)"""
ops.py                        :    24:      WHERE = auto(); MULACC = auto() # noqa: E702

ops.py                        :    25:    class ReduceOps(Enum):
ops.py                        :    26:      """A -> B (reduce)"""
ops.py                        :    27:      SUM = auto(); MAX = auto(); WMMA = auto() # noqa: E702

ops.py                        :    29:    class MetaOps(Enum):
ops.py                        :    30:      EMPTY = auto(); CONST = auto(); COPY = auto(); CONTIGUOUS = auto(); CUSTOM = auto(); ASSIGN = auto(); VIEW = auto(); KERNEL = auto() # noqa: E702

ops.py                        :    31:  Op = Union[UnaryOps, BinaryOps, ReduceOps, MetaOps, TernaryOps, BufferOps]
ops.py                        :    34:  UNSAFE_PAD_OPS = {UnaryOps.RECIP, UnaryOps.LOG2, UnaryOps.EXP2, BinaryOps.IDIV}

ops.py                        :    37:    @dataclass(frozen=True)
ops.py                        :    37:    class MemBuffer:
ops.py                        :    38:      idx: int
ops.py                        :    39:      dtype: DType
ops.py                        :    40:      st: ShapeTracker

ops.py                        :    43:    @dataclass(frozen=True)
ops.py                        :    43:    class ConstBuffer:
ops.py                        :    44:      val: ConstType | Variable
ops.py                        :    45:      dtype: DType
ops.py                        :    46:      st: ShapeTracker

ops.py                        :    49:    @dataclass(frozen=True)
ops.py                        :    49:    class KernelInfo:
ops.py                        :    50:      local_dims: int = 0           # number of local dimensions  (this is remapping RANGE to SPECIAL)
ops.py                        :    51:      upcasted: int = 0             # count that are upcasted     (this is remapping RANGE to EXPAND)
ops.py                        :    52:      dont_use_locals: bool = False # don't use local indexing

ops.py                        :    55:    @dataclass(frozen=True, eq=False)
ops.py                        :    55:    class LazyOp:
ops.py                        :    56:      op: Op
ops.py                        :    57:      src: Tuple[LazyOp, ...] = ()
ops.py                        :    58:      arg: Any = None

ops.py                        :   109:  python_alu: Dict[Op, Callable]  = {
ops.py                        :   109:    UnaryOps.LOG2: lambda x: math.log2(x) if x > 0 else -math.inf if x == 0 else math.nan,
ops.py                        :   109:    UnaryOps.EXP2: hook_overflow(math.inf, lambda x: 2**x),
ops.py                        :   109:    UnaryOps.SQRT: lambda x: math.sqrt(x) if x >= 0 else math.nan,
ops.py                        :   109:    UnaryOps.SIN: lambda x: math.sin(x) if not math.isinf(x) else math.nan,
ops.py                        :   109:    UnaryOps.RECIP: lambda x: 1/x if x != 0 else math.copysign(math.inf, x),
ops.py                        :   109:    UnaryOps.NEG: lambda x: (not x) if isinstance(x, bool) else -x,
ops.py                        :   109:    BinaryOps.SHR: operator.rshift, BinaryOps.SHL: operator.lshift,
ops.py                        :   109:    BinaryOps.MUL: operator.mul, BinaryOps.ADD: operator.add,
ops.py                        :   109:    BinaryOps.XOR: operator.xor, BinaryOps.MAX: max, BinaryOps.CMPNE: operator.ne, BinaryOps.CMPLT: operator.lt,
ops.py                        :   109:    BinaryOps.OR: operator.or_, BinaryOps.AND: operator.and_,
ops.py                        :   109:    BinaryOps.MOD: lambda x,y: abs(int(x))%abs(int(y))*(1,-1)[x<0], BinaryOps.IDIV: lambda x, y: int(x/y) if y != 0 else x*math.inf,
ops.py                        :   109:    TernaryOps.MULACC: lambda x,y,z: (x*y)+z,
ops.py                        :   109:    TernaryOps.WHERE: lambda x,y,z: y if x else z}

ops.py                        :   103:    def hook_overflow(dv, fxn):
ops.py                        :   107:      return wfxn

ops.py                        :   131:  truncate: Dict[DType, Callable] = {dtypes.bool: bool,
ops.py                        :   131:    # TODO: bfloat16
ops.py                        :   131:    dtypes.float16: truncate_fp16, dtypes.float32: lambda x: ctypes.c_float(x).value, dtypes.float64: lambda x: ctypes.c_double(x).value,
ops.py                        :   131:    dtypes.uint8: lambda x: ctypes.c_uint8(x).value, dtypes.uint16: lambda x: ctypes.c_uint16(x).value,
ops.py                        :   131:    dtypes.uint32: lambda x: ctypes.c_uint32(x).value, dtypes.uint64: lambda x: ctypes.c_uint64(x).value,
ops.py                        :   131:    dtypes.int8: lambda x: ctypes.c_int8(x).value, dtypes.int16: lambda x: ctypes.c_int16(x).value, dtypes.int32: lambda x: ctypes.c_int32(x).value \
ops.py                        :   131:        if isinstance(x,int) else x, dtypes.int64: lambda x: ctypes.c_int64(x).value, dtypes.bigint: lambda x: x }

codegen/uops.py               :    13:    # the order of these UOps controls the order of the toposort
codegen/uops.py               :    13:    class UOps(Enum):
codegen/uops.py               :    15:      SINK = auto(); VAR = auto(); EXPAND = auto(); CONTRACT = auto() # noqa: E702
codegen/uops.py               :    16:      DEFINE_GLOBAL = auto(); DEFINE_VAR = auto(); DEFINE_LOCAL = auto(); DEFINE_ACC = auto() # noqa: E702
codegen/uops.py               :    17:      CONST = auto(); SPECIAL = auto() # noqa: E702
codegen/uops.py               :    18:      NOOP = auto(); UNMUL = auto(); GEP = auto() # noqa: E702
codegen/uops.py               :    20:      CAST = auto(); BITCAST = auto(); VECTORIZE = auto() # noqa: E702
codegen/uops.py               :    21:      ALU = auto(); REDUCE = auto(); WMMA = auto() # noqa: E702
codegen/uops.py               :    23:      LOAD = auto(); STORE = auto(); PHI = auto() # noqa: E702
codegen/uops.py               :    25:      BARRIER = auto(); IF = auto(); RANGE = auto() # noqa: E702
codegen/uops.py               :    27:      ENDRANGE = auto(); ENDIF = auto() # noqa: E702

codegen/uops.py               :    29:  END_FOR_UOP = {UOps.IF:(UOps.STORE, UOps.ENDIF), UOps.RANGE:(UOps.PHI, UOps.ENDRANGE)}

codegen/uops.py               :    33:    @dataclass(frozen=True, eq=False)
codegen/uops.py               :    33:    class UOp:
codegen/uops.py               :    34:      op: UOps
codegen/uops.py               :    35:      dtype: Optional[DType] = None
codegen/uops.py               :    36:      src: Tuple[UOp, ...] = tuple()
codegen/uops.py               :    37:      arg: Any = None

codegen/transcendental.py     :     6:  TRANSCENDENTAL_SUPPORTED_DTYPES = {dtypes.float16, dtypes.float32, dtypes.float64}
codegen/uopgraph.py           :    11:  if TYPE_CHECKING:

codegen/uops.py               :    33:      @dataclass(frozen=True, eq=False)
codegen/uops.py               :    33:      class UOp:
codegen/uops.py               :    74:        @staticmethod
codegen/uops.py               :    74:        @functools.lru_cache(maxsize=None)
codegen/uops.py               :    74:        def _const(dtype:Optional[DType], b:ConstType|Variable):
codegen/uops.py               :    75:          if isinstance(b, Variable): return UOp(UOps.DEFINE_VAR, dtype, (), b)
codegen/uops.py               :    76:          return UOp(UOps.CONST, dtype, arg=dtypes.as_const(b, dtype) if dtype is not None else b)

codegen/uopgraph.py           :    53:  float4_folding = PatternMatcher([
codegen/uopgraph.py           :    53:    # reorder index to bring const closer to store
codegen/uopgraph.py           :    53:    (UOp(UOps.STORE, src=(UOp.var("buf"), UOp.var("idx")+
codegen/uopgraph.py           :    53:      (UOp(UOps.EXPAND, src=tuple(UOp.const(dtypes.int, i) for i in range(4))).name("ex")+UOp.var("idx2")), UOp.var("var"))).name("store"),
codegen/uopgraph.py           :    53:      lambda buf, store, idx, idx2, ex, var: UOp(UOps.STORE, store.dtype, (buf, idx+idx2+ex, var), store.arg)),
codegen/uopgraph.py           :    53:    # float(2,4) load
codegen/uopgraph.py           :    53:    (UOp(UOps.LOAD, src=(UOp.var("buf"), UOp(UOps.EXPAND).name("ex")+UOp.var("idx")+UOp.var("idx2"))).name("load"), float4_expand_load),
codegen/uopgraph.py           :    53:    (UOp(UOps.LOAD, src=(UOp.var("buf"), UOp(UOps.EXPAND).name("ex")+UOp.var("idx"))).name("load"), float4_expand_load),
codegen/uopgraph.py           :    53:    (UOp(UOps.LOAD, src=(UOp.var("buf"), UOp(UOps.EXPAND).name("ex"))).name("load"), float4_expand_load),
codegen/uopgraph.py           :    53:    # float(2,4) store
codegen/uopgraph.py           :    53:    # TODO: fold ADDs into one UOp and remove add chains
codegen/uopgraph.py           :    53:    (UOp(UOps.STORE, src=(UOp.var("buf"),
codegen/uopgraph.py           :    53:      UOp(UOps.EXPAND).name("ex")+UOp.var("idx")+UOp.var("idx2")+UOp.var("idx3"), UOp.var("var"))).name("store_allow_any_len"),
codegen/uopgraph.py           :    53:      float4_contract_store),
codegen/uopgraph.py           :    53:    (UOp(UOps.STORE, src=(UOp.var("buf"),
codegen/uopgraph.py           :    53:      UOp(UOps.EXPAND).name("ex")+UOp.var("idx")+UOp.var("idx2"), UOp.var("var"))).name("store_allow_any_len"),
codegen/uopgraph.py           :    53:      float4_contract_store),
codegen/uopgraph.py           :    53:    (UOp(UOps.STORE, src=(UOp.var("buf"),
codegen/uopgraph.py           :    53:      UOp(UOps.EXPAND).name("ex")+UOp.var("idx"), UOp.var("var"))).name("store_allow_any_len"), float4_contract_store),
codegen/uopgraph.py           :    53:    (UOp(UOps.STORE, src=(UOp.var("buf"),
codegen/uopgraph.py           :    53:      UOp(UOps.EXPAND).name("ex"), UOp.var("var"))).name("store_allow_any_len"), float4_contract_store),
codegen/uopgraph.py           :    53:    # image handling
codegen/uopgraph.py           :    53:    (UOp(UOps.LOAD, src=(UOp.var("buf"), UOp(UOps.VECTORIZE, dtypes.int.vec(3), (UOp.var('idx'), UOp.var('idy'),
codegen/uopgraph.py           :    53:       UOp.var('id4'))))).name("ls_allow_any_len"), image_contract_load),
codegen/uopgraph.py           :    53:    (UOp(UOps.STORE, src=(UOp.var("buf"), UOp(UOps.VECTORIZE, dtypes.int.vec(3), (UOp.var('idx'), UOp.var('idy'),
codegen/uopgraph.py           :    53:       UOp(UOps.EXPAND, src=tuple(UOp.const(dtypes.int, i) for i in range(4))).name("ex"))), UOp.var("var"))).name("ls_allow_any_len"),
codegen/uopgraph.py           :    53:       image_contract_store),
codegen/uopgraph.py           :    53:  ])

dtype.py                      :     9:    @dataclass(frozen=True, order=True)
dtype.py                      :     9:    class DType:
dtype.py                      :    16:      def vec(self, sz:int):
dtype.py                      :    17:        assert sz > 1 and self.count == 1, f"can't vectorize {self} with size {sz}"
dtype.py                      :    18:        return DType(self.priority, self.itemsize*sz, f"{INVERSE_DTYPES_DICT[self.name]}{sz}", None, sz)

codegen/uops.py               :   145:    class PatternMatcher:
codegen/uops.py               :   146:      def __init__(self, patterns:List[Tuple[Union[UPat, UOp], Callable]]):
codegen/uops.py               :   147:        self.patterns = patterns
codegen/uops.py               :   148:        self.pdict: DefaultDict[Tuple[UOps, Any], List[Tuple[UPat, Callable]]] = defaultdict(list)
codegen/uops.py               :   150:        for p,fxn in self.patterns:
codegen/uops.py               :   151:          if isinstance(p, UOp): p = UPat.compile(p)

codegen/uops.py               :   100:      class UPat:
codegen/uops.py               :   120:        @staticmethod
codegen/uops.py               :   120:        def compile(u: UOp, name:Optional[str]=None) -> UPat:
codegen/uops.py               :   121:          if u.op is UOps.VAR: return UPat(name=name or u.arg, dtype=u.dtype) if len(u.src) == 0 else UPat.compile(u.src[0], name or u.arg)

codegen/uops.py               :   100:        class UPat:
codegen/uops.py               :   120:          @staticmethod
codegen/uops.py               :   120:          def compile(u: UOp, name:Optional[str]=None) -> UPat:
codegen/uops.py               :   122:            return UPat(u.op, u.arg, (list if u.commutative() else tuple)([UPat.compile(src) for src in u.src]) if u.src != () else None,
codegen/uops.py               :   122:                        name, u.dtype, allow_any_len=(isinstance(name, str) and 'allow_any_len' in name))

codegen/uops.py               :    33:          @dataclass(frozen=True, eq=False)
codegen/uops.py               :    33:          class UOp:
codegen/uops.py               :    38:            def commutative(self) -> bool:
codegen/uops.py               :    39:              return self.op is UOps.UNMUL or (self.op is UOps.ALU and \
codegen/uops.py               :    39:                self.arg in {BinaryOps.ADD, BinaryOps.MUL, BinaryOps.MAX, BinaryOps.CMPNE, BinaryOps.XOR, BinaryOps.AND, BinaryOps.OR})

codegen/uops.py               :   100:            class UPat:
codegen/uops.py               :   101:              def __init__(self, op:Optional[Union[UOps, Set[UOps]]]=None, arg:Any=None, src:Optional[Union[Tuple[UPat, ...], List[UPat], UPat]]=None,
codegen/uops.py               :   101:                           name:Optional[str]=None, dtype:Optional[Union[DType, Set[DType]]]=None, allow_any_len:bool=False):
codegen/uops.py               :   103:                self.op: Optional[Tuple[UOps, ...]] = None if op is None else (tuple(op) if isinstance(op, set) else (op,))
codegen/uops.py               :   104:                self.dtype: Optional[Tuple[DType, ...]] = None if dtype is None else (tuple(dtype) if isinstance(dtype, set) else (dtype,))
codegen/uops.py               :   105:                self.arg = arg
codegen/uops.py               :   106:                self.src: Any = None
codegen/uops.py               :   107:                if isinstance(src, list):
codegen/uops.py               :   110:                elif isinstance(src, tuple):
codegen/uops.py               :   113:                elif isinstance(src, UPat):
codegen/uops.py               :   116:                self.name: Optional[str] = name
codegen/uops.py               :   117:                self.allowed_len: int = 0 if allow_any_len or isinstance(src, UPat) or src is None else len(src)

codegen/uops.py               :   100:                class UPat:
codegen/uops.py               :   101:                  def __init__(self, op:Optional[Union[UOps, Set[UOps]]]=None, arg:Any=None, src:Optional[Union[Tuple[UPat, ...], List[UPat], UPat]]=None,
codegen/uops.py               :   101:                               name:Optional[str]=None, dtype:Optional[Union[DType, Set[DType]]]=None, allow_any_len:bool=False):
codegen/uops.py               :   112:                      self.src = [src]

codegen/uops.py               :   100:          class UPat:
codegen/uops.py               :   101:            def __init__(self, op:Optional[Union[UOps, Set[UOps]]]=None, arg:Any=None, src:Optional[Union[Tuple[UPat, ...], List[UPat], UPat]]=None,
codegen/uops.py               :   101:                         name:Optional[str]=None, dtype:Optional[Union[DType, Set[DType]]]=None, allow_any_len:bool=False):
codegen/uops.py               :   109:                self.src = list(itertools.permutations(src))

codegen/uops.py               :   152:        assert p.op is not None
codegen/uops.py               :   153:        for uop in p.op: self.pdict[(uop, p.arg)].append((p, fxn))
codegen/uopgraph.py           :   149:    (UOp(UOps.REDUCE, src=(UOp(UOps.EXPAND, src=tuple(UOp(UOps.GEP, dtypes.float, src=(UOp.var('x'),), arg=i) for i in range(2))).name("expand"),))
codegen/uopgraph.py           :   149:     .name("reduce_allow_any_len"), reduce_before_expand),
codegen/uopgraph.py           :   151:    (UOp(UOps.REDUCE, src=(UOp(UOps.EXPAND, src=tuple(UOp(UOps.GEP, dtypes.float, src=(UOp.var('x'),), arg=i) for i in range(8))).name("expand"),))
codegen/uopgraph.py           :   151:     .name("reduce_allow_any_len"), reduce_before_expand),
codegen/uopgraph.py           :   153:    (UOp.var("add") + UOp(UOps.WMMA).name("wmma"),
codegen/uopgraph.py           :   153:      lambda add, wmma: UOp(wmma.op, wmma.dtype, (wmma.src[0], wmma.src[1], wmma.src[2]+add), wmma.arg)),
codegen/uopgraph.py           :   156:    (UOp(UOps.ALU, dtype=dtypes.uint64, src=(UOp.var("x"), UOp.var("seed")), arg=BinaryOps.THREEFRY), threefry2x32),
codegen/uopgraph.py           :   158:    (UOp.where(UOp.alu(BinaryOps.CMPLT, UOp.alu(BinaryOps.ADD, UOp.var("idx"), UOp.alu(BinaryOps.MUL,
codegen/uopgraph.py           :   158:      UOp.cvar("mval"), UOp(UOps.RANGE, src=(UOp.var("loop_start"), UOp.var("loop_end"))).name("rng"))),
codegen/uopgraph.py           :   158:      UOp.cvar("compval")), UOp.cvar("multconst"), UOp.const(None,0)), loop_collapse),
codegen/uopgraph.py           :   161:    (UOp.where(UOp.alu(BinaryOps.CMPLT, UOp.alu(BinaryOps.ADD, UOp.var("idx"), UOp.alu(UnaryOps.NEG,
codegen/uopgraph.py           :   161:      UOp(UOps.RANGE, src=(UOp.var("loop_start"), UOp.var("loop_end"))).name("rng"))),
codegen/uopgraph.py           :   161:      UOp.cvar("compval")), UOp.cvar("multconst"), UOp.const(None, 0)),
codegen/uopgraph.py           :   161:      lambda **kwargs: loop_collapse(mval=UOp.const(dtypes.int, -1), **kwargs)),
codegen/uopgraph.py           :   166:    (UPat(UOps.PHI, src=(UPat(UOps.DEFINE_ACC, name="phi_input", src=[UPat(UOps.CONST), UPat(UOps.RANGE, name="loop")]),
codegen/uopgraph.py           :   166:                         UPat(UOps.ALU, BinaryOps.ADD, src=(UPat(name="val1"), UPat(name="val2"))))), sum_collapse),
codegen/uopgraph.py           :   168:    (UPat(UOps.PHI, src=(UPat(UOps.GEP, name="phi_input", src=(UPat(UOps.DEFINE_ACC, src=[UPat(UOps.CONST), UPat(UOps.RANGE, name="loop")]),)),
codegen/uopgraph.py           :   168:                         UPat(UOps.ALU, BinaryOps.ADD, src=(UPat(name="val1"), UPat(name="val2"))))), sum_collapse),
codegen/uopgraph.py           :   171:    (UOp.cvar('c1') * UOp(UOps.UNMUL, src=(UOp.cvar('c2'), UOp.var('v'))), lambda c1,c2,v: v if c1.arg == c2.arg else None),
codegen/uopgraph.py           :   172:    (UOp.cvar('c1') * (UOp.var('add') + UOp(UOps.UNMUL, src=(UOp.cvar('c2'), UOp.var('v')))),
codegen/uopgraph.py           :   172:      lambda c1, add, c2, v: (add*c1+v) if c1.arg == c2.arg else None),
codegen/uopgraph.py           :   174:    (UOp(UOps.UNMUL, src=(UOp.const(None, 0).name('zero'), UOp.var())), lambda zero: zero),
codegen/uopgraph.py           :   175:    (UOp(UOps.UNMUL).name('unmul').cast().name('root'), lambda root,unmul: UOp(UOps.UNMUL, root.dtype, (unmul.src[0].cast(root.dtype), unmul.src[1]))),
codegen/uopgraph.py           :   177:    (UOp.var('idx').eq(UOp(UOps.RANGE).name("rng")).cast()*
codegen/uopgraph.py           :   177:      UOp(UOps.LOAD, src=(UOp.var("buf"), UOp.var('add')+UOp.var('mul')*UOp(UOps.RANGE).name("rng"))).name("ld"),
codegen/uopgraph.py           :   177:      lambda idx,rng,buf,add,mul,ld: UOp(UOps.UNMUL, ld.dtype, (UOp(ld.op, ld.dtype, (buf, add+mul*idx)), rng.src[1]-rng.src[0]))),
codegen/uopgraph.py           :   180:    (UOp.var('idx').eq(UOp(UOps.RANGE).name("rng")).where(
codegen/uopgraph.py           :   180:      UOp(UOps.LOAD, src=(UOp.var("buf"), UOp.var('add')+UOp.var('mul')*UOp(UOps.RANGE).name("rng"))).name("ld"), UOp.const(None, 0.0)),
codegen/uopgraph.py           :   180:      lambda idx,rng,buf,add,mul,ld: UOp(UOps.UNMUL, ld.dtype, (UOp(ld.op, ld.dtype, (buf, add+mul*idx)), rng.src[1]-rng.src[0]))),
codegen/uopgraph.py           :   184:    (UOp.cvar("c1") - (UOp.var("x") + UOp.cvar("c2")), lambda c1, c2, x: (c1-c2)-x),  # c1 - (x + c2) -> (c1-c2) - x
codegen/uopgraph.py           :   186:    (UOp.max(UOp.cvar('c'), UOp(UOps.SPECIAL).name('s')), lambda c,s: c if (s.arg[2]-1) <= c.arg else None),
codegen/uopgraph.py           :   187:    (UOp.max(UOp.cvar('c'), UOp(UOps.SPECIAL).name('s')+UOp.cvar('c2')), lambda c,s,c2: (s+c2) if 0 >= c.arg else None),  # TODO: generic
codegen/uopgraph.py           :   188:    (UOp.max(UOp.cvar('c'), -(UOp(UOps.SPECIAL).name('s')+UOp.cvar('c2'))), lambda c,s,c2: -(s+c2) if -(s.arg[2]-1+c2.arg) >= c.arg else None),
codegen/uopgraph.py           :   190:    (UOp.max(UOp.cvar('c'), UOp(UOps.RANGE).name('s')), lambda c,s: s if s.src[0].arg >= c.arg else None),  # TODO: generic
codegen/uopgraph.py           :   191:    (UOp.max(UOp.cvar('c'), UOp(UOps.RANGE).name('s')+UOp.cvar('c2')), lambda c,s,c2: (s+c2) if s.src[0].arg >= c.arg else None),  # TODO: generic
codegen/uopgraph.py           :   192:    (UOp.max(UOp.cvar('c'), -(UOp(UOps.RANGE).name('s'))), lambda c,s: -s if -(s.src[1].arg-1) >= c.arg else None),
codegen/uopgraph.py           :   193:    (UOp.max(UOp.cvar('c'), -(UOp(UOps.RANGE).name('s')+UOp.cvar('c2'))), lambda c,s,c2: -(s+c2) if -(s.src[1].arg-1+c2.arg) >= c.arg else None),
codegen/uopgraph.py           :   195:    (UOp(UOps.GEP, src=(UOp.cvar("c"),)).name("root"), lambda root, c: UOp.const(root.dtype, c.arg)),
codegen/uopgraph.py           :   196:    (UPat(UOps.CAST, name="root", src=UPat(UOps.CONST, name="c")), lambda root, c: UOp.const(root.dtype, c.arg)),

codegen/uops.py               :   100:    class UPat:
codegen/uops.py               :   101:      def __init__(self, op:Optional[Union[UOps, Set[UOps]]]=None, arg:Any=None, src:Optional[Union[Tuple[UPat, ...], List[UPat], UPat]]=None,
codegen/uops.py               :   101:                   name:Optional[str]=None, dtype:Optional[Union[DType, Set[DType]]]=None, allow_any_len:bool=False):
codegen/uops.py               :   115:          self.src = [itertools.repeat(src)]

codegen/uopgraph.py           :   197:    (UPat(UOps.VECTORIZE, name="root", src=UPat(UOps.CONST, name="c")), lambda root, c: UOp.const(root.dtype, c.arg)),
codegen/uopgraph.py           :   199:    (UOp(UOps.PHI, src=(UOp(UOps.DEFINE_ACC).name("acc"), UOp.var("acc"))), lambda acc: UOp.cast(acc.src[0], acc.dtype)),
codegen/uopgraph.py           :   200:    (UOp(UOps.PHI, src=(UOp(UOps.DEFINE_ACC, src=(UOp.cvar(),)), UOp.var("x"))), lambda x: x),
codegen/uopgraph.py           :   201:    (UOp(UOps.PHI, src=(UOp.cvar(), UOp.var("x"))), lambda x: x),
codegen/uopgraph.py           :   203:    (UOp(UOps.DEFINE_ACC, src=(UOp.cvar(),)).name("root"), lambda root: UOp.cast(root.src[0], root.dtype)),
codegen/uopgraph.py           :   204:    (UOp(UOps.GEP, src=(UOp.cvar("x"),)).name("root"), lambda root,x: UOp.const(root.dtype, x.arg)),
codegen/uopgraph.py           :   206:    (UOp.max(UOp.var('x'), UOp.const(dtypes.int, -2147483648)), lambda x: x),
codegen/uopgraph.py           :   208:    (UOp.var().lt(UOp.const(dtypes.bool, False)), lambda: UOp.const(dtypes.bool, False)),
codegen/uopgraph.py           :   209:    (UOp.const(dtypes.bool, True).lt(UOp.var()), lambda: UOp.const(dtypes.bool, False)),
codegen/uopgraph.py           :   211:    (UOp.var().where(UOp.var("val"), UOp.var("val")), lambda val: val),
codegen/uopgraph.py           :   212:    (UOp.cvar('gate').where(UOp.var('c0'), UOp.var('c1')), lambda gate, c0, c1: c0 if gate.arg else c1),
codegen/uopgraph.py           :   214:    (UPat(UOps.ALU, name="root", src=UPat(UOps.CONST)), lambda root: UOp.const(root.dtype, exec_alu(root.arg, root.dtype, [x.arg for x in root.src]))),
codegen/uopgraph.py           :   216:    (-(-UOp.var('x')), lambda x: x),    # -(-x) -> x
codegen/uopgraph.py           :   217:    (UOp.var('x') + 0, lambda x: x),    # x+0 -> x
codegen/uopgraph.py           :   218:    (UOp.var('x') * 1, lambda x: x),    # x*1 -> x
codegen/uopgraph.py           :   219:    (UOp.var('x') * -1, lambda x: -x),  # x*-1 -> -x
codegen/uopgraph.py           :   220:    (UOp.var('x') // UOp.var('x'), lambda x: UOp.const(x.dtype, 1)), # x//x -> 1
codegen/uopgraph.py           :   221:    (UOp.var('x') // 1, lambda x: x),   # x//1 -> x
codegen/uopgraph.py           :   222:    (UOp.var('x') // -1, lambda x: -x), # x//-1 -> -x
codegen/uopgraph.py           :   223:    (UOp.var('x') / UOp.var('x'), lambda x: UOp.const(x.dtype, 1)), # x/x -> 1
codegen/uopgraph.py           :   224:    (UOp.var('x') / UOp.cvar('c'), lambda x,c: x*exec_alu(UnaryOps.RECIP, c.dtype, [c.arg])),    # x/c -> x*(1/c)
codegen/uopgraph.py           :   225:    (UOp.var('x', dtype=dtypes.bool).max(UOp.const(dtypes.bool, False)), lambda x: x),  # max(x, False) -> x
codegen/uopgraph.py           :   230:    (UOp.var('x') * 0, lambda x: UOp.const(x.dtype, float('nan') if isinstance(x.arg, float) and (math.isnan(x.arg) or math.isinf(x.arg)) else 0)),
codegen/uopgraph.py           :   231:    (UOp.var('x') - UOp.var('x'), lambda x: UOp.const(x.dtype, 0)),   # x-x -> 0
codegen/uopgraph.py           :   233:    (UOp.store(UOp.var("buf"), UOp.var("idx"), UOp.load(UOp.var("buf"), UOp.var("idx"))), lambda buf,idx:UOp(UOps.NOOP)),
codegen/uopgraph.py           :   235:    ((UOp.var('x') + UOp.cvar('c1')) + UOp.cvar('c2'), lambda x,c1,c2: x+UOp.const(x.dtype, exec_alu(BinaryOps.ADD, x.dtype, [c1.arg, c2.arg]))),
codegen/uopgraph.py           :   236:    ((UOp.var('x') - UOp.cvar('c1')) + UOp.cvar('c2'), lambda x,c1,c2: x+UOp.const(x.dtype, exec_alu(BinaryOps.ADD, x.dtype, [c2.arg, -c1.arg]))),
codegen/uopgraph.py           :   239:    ((UOp.cvar('c')*UOp.var('x')) % UOp.cvar('c'), lambda x,c: x.const(0)),
codegen/uopgraph.py           :   240:    (((UOp.cvar('c')*UOp.var('x'))+UOp.var('x2')) % UOp.cvar('c'), lambda x,c,x2: x2%c),
codegen/uopgraph.py           :   242:    ((UOp.var("x") * UOp.cvar("c1")) * UOp.cvar("c2"), lambda x,c1,c2: x*UOp.const(x.dtype, exec_alu(BinaryOps.MUL, x.dtype, [c1.arg, c2.arg]))),
codegen/uopgraph.py           :   246:    (UOp.var("x") % UOp.const(None, 1), lambda x: UOp.const(x.dtype, 0)),
codegen/uopgraph.py           :   248:    (UOp.var("x") * UOp.cvar("c0") + UOp.var("x") * UOp.cvar("c1"), lambda x,c0,c1: x*exec_alu(BinaryOps.ADD, x.dtype, [c0.arg, c1.arg])),
codegen/uopgraph.py           :   252:    ((UOp.var("x") * UOp.cvar("c0")) // UOp.cvar("c0"), lambda x,c0: x if c0.arg != 0 else None),
codegen/uopgraph.py           :   254:    ((UOp.var("x") * UOp.var("x2")) / UOp.var("x2"), lambda x,x2: x),
codegen/uopgraph.py           :   256:    ((UOp.var("x") // UOp.cvar("c0")) // UOp.cvar("c1"), lambda x,c0,c1: x//UOp.const(x.dtype, exec_alu(BinaryOps.MUL, x.dtype, [c0.arg, c1.arg]))),
codegen/uopgraph.py           :   258:    ((UOp.var("x") / UOp.var("x2")) / UOp.var("x3"), lambda x,x2,x3: x/(x2*x3)),
codegen/uopgraph.py           :   260:    ((UOp.cvar("c0") + UOp.var("x")).lt(UOp.cvar("c1")),
codegen/uopgraph.py           :   260:      lambda x,c0,c1: UOp.lt(x, UOp.const(x.dtype, exec_alu(BinaryOps.ADD, x.dtype, [c1.arg, -c0.arg])))),
codegen/uopgraph.py           :   263:    (UOp.var("x") + UOp.var("x") * UOp.cvar("c0"), lambda x,c0: x*UOp.const(x.dtype, c0.arg+1)),
codegen/uopgraph.py           :   265:    (UOp.var("x").ne(0), lambda x: x.cast(dtypes.bool)),
codegen/uopgraph.py           :   267:    (UOp.var("x", dtype=dtypes.bool).ne(1), lambda x: -x),
codegen/uopgraph.py           :   269:    (UOp.store(UOp.var("buf"), UOp.var("idx"), UOp.alu(TernaryOps.WHERE, UOp.var("gate"), UOp.var("alt"), UOp.load(UOp.var("buf"), UOp.var("idx")))),
codegen/uopgraph.py           :   269:     lambda buf, idx, gate, alt: UOp.store(buf, idx, alt, gate)),
codegen/uopgraph.py           :   272:    (UOp(UOps.VECTORIZE, src=tuple(UOp(UOps.PHI, src=(UOp(UOps.GEP, src=(UOp.var("val"),), arg=i), UOp.var(f"v{i}"))) for i in range(4))).name("root"),
codegen/uopgraph.py           :   272:     lambda root, val, v0, v1, v2, v3: UOp(UOps.PHI, root.dtype, (val, UOp(UOps.VECTORIZE, val.dtype, (v0, v1, v2, v3))))),
codegen/uopgraph.py           :   274:    (UOp(UOps.VECTORIZE, src=tuple(UOp(UOps.PHI, src=(UOp(UOps.GEP, src=(UOp.var("val"),), arg=i), UOp.var(f"v{i}"))) for i in range(2))).name("root"),
codegen/uopgraph.py           :   274:     lambda root, val, v0, v1: UOp(UOps.PHI, root.dtype, (val, UOp(UOps.VECTORIZE, val.dtype, (v0, v1))))),
codegen/uopgraph.py           :   277:    (UOp.lt(-UOp.var('x'), UOp.cvar('c', dtypes.int)), lambda c,x: UOp.lt(UOp.const(c.dtype, -c.arg), x)),
codegen/uopgraph.py           :   279:    (UOp(UOps.CAST).name("root"), lambda root: root.src[0] if str(root.dtype) == str(root.src[0].dtype) else None),
codegen/uopgraph.py           :   280:    (UOp(UOps.VECTORIZE).name("root"), lambda root: root.src[0] if str(root.dtype) == str(root.src[0].dtype) else None),
codegen/uopgraph.py           :   282:    (UOp.load(UOp.var("buf"), UOp.var("idx"), UOp.const(dtypes.bool, True), UOp.cvar("var")), lambda buf,idx,var: UOp.load(buf, idx, dtype=var.dtype)),
codegen/uopgraph.py           :   283:    (UOp.load(UOp.var("buf"), UOp.var("idx"), UOp.const(dtypes.bool, True), UOp.cvar("var"), UOp.var("barrier")),
codegen/uopgraph.py           :   283:     lambda buf,idx,var,barrier: UOp.load(buf, idx, barrier, dtype=var.dtype)),
codegen/uopgraph.py           :   285:    (UOp.load(UOp.var(), UOp.var(), UOp.const(dtypes.bool, False), UOp.cvar("var")), lambda var: var),
codegen/uopgraph.py           :   286:    (UOp.load(UOp.var(), UOp.var(), UOp.const(dtypes.bool, False), UOp.cvar("var"), UOp.var()), lambda var: var),
codegen/uopgraph.py           :   287:    (UOp.store(UOp.var("buf"), UOp.var("idx"), UOp.var("val"), UOp.const(dtypes.bool, True)), UOp.store),
codegen/uopgraph.py           :   288:    (UOp.store(UOp.var(), UOp.var(), UOp.var(), UOp.const(dtypes.bool, False)), lambda: UOp(UOps.NOOP)),
codegen/uopgraph.py           :   290:    (UOp(UOps.SINK).name("root"),
codegen/uopgraph.py           :   290:      lambda root: UOp(UOps.SINK, root.dtype, a, root.arg) if len(a:=tuple(x for x in root.src if x.op is not UOps.NOOP)) != len(root.src) else None),
codegen/uopgraph.py           :   345:  acc_number = 0
codegen/uopgraph.py           :   394:  expander = PatternMatcher([
codegen/uopgraph.py           :   394:    (UPat({UOps.ALU, UOps.CAST, UOps.BITCAST, UOps.GEP, UOps.WMMA, UOps.LOAD, UOps.STORE,
codegen/uopgraph.py           :   394:           UOps.VECTORIZE, UOps.REDUCE, UOps.EXPAND, UOps.IF}, name="root"), do_expand),
codegen/uopgraph.py           :   394:    (UOp(UOps.REDUCE).name("root"), do_reduce_with_expand),
codegen/uopgraph.py           :   394:    (UOp(UOps.CONTRACT).name("con"), do_contract),
codegen/uopgraph.py           :   394:    # remove EXPANDs from SINK
codegen/uopgraph.py           :   394:    (UOp(UOps.SINK).name("root"),
codegen/uopgraph.py           :   394:     lambda root: UOp(UOps.SINK, root.dtype, a, root.arg)
codegen/uopgraph.py           :   394:      if len(a:=tuple(flatten(x.src if x.op is UOps.EXPAND else (x,) for x in root.src))) != len(root.src) else None),
codegen/uopgraph.py           :   394:    # BARRIERs aren't actually expanded
codegen/uopgraph.py           :   394:    (UOp(UOps.BARRIER, src=(UOp(UOps.EXPAND).name("ex"),)), lambda ex: UOp(UOps.EXPAND, None, (UOp(UOps.BARRIER, None, ex.src),)*len(ex.src), ex.arg)),
codegen/uopgraph.py           :   394:    # empty EXPAND is NOOP
codegen/uopgraph.py           :   394:    (UOp(UOps.EXPAND, src=(UOp.var('x'),), arg=()), lambda x: x),
codegen/uopgraph.py           :   394:    # no ALU on vectorized dtypes
codegen/uopgraph.py           :   394:    (UPat({UOps.ALU, UOps.CAST}, name="alu"), no_vectorized_alu),
codegen/uopgraph.py           :   394:  ])

codegen/uopgraph.py           :   432:    class UOpGraph:
codegen/uopgraph.py           :   464:      cnt = 0

renderer/__init__.py          :    10:    @dataclass(frozen=True)
renderer/__init__.py          :    10:    class TensorCore: # D = A * B + C, A is (M x K), B is (K x N), C and D are (M x N)
renderer/__init__.py          :    11:      dims: Tuple[int,int,int] # N, M, K
renderer/__init__.py          :    12:      dtype_in: DType # dtype for A and B
renderer/__init__.py          :    13:      dtype_out: DType # dtype for C and D
renderer/__init__.py          :    14:      threads: List[Tuple[int,int]] # list of (TC dim,amt) that construct the warp thread structure
renderer/__init__.py          :    15:      thread_local_sizes: List[List[int]] # in each thread, the number of elements stored in registers for each TC dim

renderer/__init__.py          :    19:    @dataclass(frozen=True)
renderer/__init__.py          :    19:    class Program:
renderer/__init__.py          :    20:      name:str
renderer/__init__.py          :    21:      src:str
renderer/__init__.py          :    22:      dname:str
renderer/__init__.py          :    23:      global_size:Optional[List[int]]=None
renderer/__init__.py          :    24:      local_size:Optional[List[int]]=None
renderer/__init__.py          :    25:      uops:Optional[UOpGraph]=None
renderer/__init__.py          :    26:      op_estimate:sint=0
renderer/__init__.py          :    27:      mem_estimate:sint=0

renderer/__init__.py          :    46:    class Renderer:
renderer/__init__.py          :    47:      device: str = ""
renderer/__init__.py          :    48:      suffix: str = ""
renderer/__init__.py          :    50:      supports_float4: bool = True
renderer/__init__.py          :    51:      has_local: bool = True
renderer/__init__.py          :    52:      has_shared: bool = True
renderer/__init__.py          :    54:      global_max: Optional[Tuple[int, ...]] = (0x8FFFFFFF,) * (3) # TODO: UOps.SPECIAL int32 indexes right now
renderer/__init__.py          :    55:      local_max: Optional[Tuple[int, ...]] = (0x8FFFFFFF,) * (3) # TODO: UOps.SPECIAL int32 indexes right now
renderer/__init__.py          :    56:      shared_max: int = 32768
renderer/__init__.py          :    57:      tensor_cores: List[TensorCore] = []

device.py                     :    39:  Device = _Device()

device.py                     :    44:    @dataclass(frozen=True, eq=True)
device.py                     :    44:    class BufferOptions:
device.py                     :    45:      image: Optional[ImageDType] = None
device.py                     :    46:      uncached: bool = False
device.py                     :    47:      cpu_access: bool = False
device.py                     :    48:      host: bool = False
device.py                     :    49:      nolru: bool = False

device.py                     :   142:    class LRUAllocator(Allocator):  # pylint: disable=abstract-method
device.py                     :   143:      """

device.py                     :   169:  MallocAllocator = _MallocAllocator()

device.py                     :   217:    class HWCommandQueue:
device.py                     :   218:      """

device.py                     :   199:      def hcq_command(func):
device.py                     :   215:        return __wrapper

device.py                     :   418:    class HCQCompiled(Compiled):
device.py                     :   419:      """

device.py                     :   470:    class HCQAllocator(LRUAllocator): # pylint: disable=abstract-method
device.py                     :   471:      """

lazy.py                       :    11:  lazycache: WeakValueDictionary[Any, LazyBuffer] = WeakValueDictionary()
lazy.py                       :    24:  view_supported_devices = {"LLVM", "CLANG", "CUDA", "NV", "AMD", "METAL", "DISK"}

lazy.py                       :    25:    class LazyBuffer:
lazy.py                       :    27:                   op:Optional[Op]=None, arg:Any=None, srcs:Tuple[LazyBuffer, ...]=(),
lazy.py                       :    28:                   base:Optional[LazyBuffer]=None, metadata:Optional[Metadata]=None):
lazy.py                       :    28:        self.device, self.st, self.dtype, self.shape, self.size, self.metadata = device, st, dtype, st.shape, st.size, metadata
lazy.py                       :    28:        self._base: Optional[LazyBuffer] = None
lazy.py                       :    28:        if base is None:
lazy.py                       :    28:          # properties on base
lazy.py                       :    28:          self.op, self.arg, self.srcs = op, arg, srcs  # this is a LazyOp, except the src is LazyBuffers and not LazyOps
lazy.py                       :    28:          assert self.op is not MetaOps.ASSIGN or srcs[1].base.realized is not None, "assign target must be realized"
lazy.py                       :    28:          if self.op is MetaOps.VIEW:
lazy.py                       :    28:            # some LazyBuffers can be processed with only a view, no AST required
lazy.py                       :    28:            self.buffer: Buffer = srcs[0].base.buffer.view(st.size, dtype, srcs[0].st.views[0].offset * srcs[0].dtype.itemsize)
lazy.py                       :    28:          else:
lazy.py                       :    28:            self.buffer = srcs[1].base.buffer if self.op is MetaOps.ASSIGN else Buffer(device, self.size, dtype)
lazy.py                       :    28:          self.buffer.ref(1)
lazy.py                       :    28:          self.contiguous_child: Optional[Tuple[ReferenceType[LazyBuffer], ShapeTracker]] = None
lazy.py                       :    28:          self.forced_realize = False
lazy.py                       :    28:        else:
lazy.py                       :    28:          # properties on view
lazy.py                       :    28:          assert base.base == base, "base must be a base itself"
lazy.py                       :    28:          self._base = base
lazy.py                       :    28:      def __del__(self):
lazy.py                       :    28:        if hasattr(self, 'buffer'): self.buffer.ref(-1)
lazy.py                       :    28:      def __repr__(self) -> str:
lazy.py                       :    28:        return f"<LB {self.device} {self.shape} {str(self.dtype)[7:]} {self.st if self.base != self else (self.op, self.realized)}>"
lazy.py                       :    28:      @property
lazy.py                       :    28:      def realized(self) -> Optional[Buffer]:
lazy.py                       :    28:        # NOTE: we check for a lack of srcs instead of an allocated buffer to make unrealized assigns return None here
lazy.py                       :    28:        return self.buffer if self._base is None and not hasattr(self, 'srcs') else None
lazy.py                       :    28:      # NOTE: this has to be a function to prevent self reference
lazy.py                       :    28:      @property
lazy.py                       :    28:      def base(self) -> LazyBuffer: return self._base if self._base is not None else self
lazy.py                       :    28:      # same API as multi
lazy.py                       :    28:      @property
lazy.py                       :    28:      def lbs(self) -> List[LazyBuffer]: return [self]
lazy.py                       :    28:      @staticmethod
lazy.py                       :    28:      def metaop(op, shape:Tuple[sint,...], dtype:DType, device:str, arg=None, src:Tuple[LazyBuffer, ...]=(), enable_cache=False) -> LazyBuffer:
lazy.py                       :    28:        assert isinstance(src, tuple)
lazy.py                       :    28:        return create_lazybuffer(device, ShapeTracker.from_shape(shape), dtype, op, arg, src, enable_cache=enable_cache)
lazy.py                       :    28:      def const(self, val:ConstType, shape:Optional[Tuple[sint,...]]=None) -> LazyBuffer:
lazy.py                       :    28:        assert isinstance(val, (int,float,bool)), f"{val=} has {type(val)=}, not a ConstType"
lazy.py                       :    28:        shape = self.shape if shape is None else shape
lazy.py                       :    28:        return LazyBuffer.metaop(MetaOps.CONST, tuple(), self.dtype, self.device, arg=val).reshape((1,)*len(shape)).expand(shape)
lazy.py                       :    28:      def is_realized(self) -> bool: return self.base.realized is not None
lazy.py                       :    28:      def assign(self, x:LazyBuffer) -> LazyBuffer:
lazy.py                       :    28:        assert x.size == self.size, f"assign target must have same size {self.size=} != {x.size=}"
lazy.py                       :    28:        return LazyBuffer.metaop(MetaOps.ASSIGN, self.shape, self.dtype, self.device, arg=() if self.st.contiguous else (self.st,), src=(x, self.base))
lazy.py                       :    28:      def can_view(self): return self.st.consecutive and not self.is_unrealized_const() and self.device.split(":")[0] in view_supported_devices
lazy.py                       :    28:      def contiguous(self, allow_buffer_view=True):
lazy.py                       :    28:        if not self.st.contiguous or self.size != self.base.size or self.is_unrealized_const():
lazy.py                       :    28:          ret = self.e(MetaOps.VIEW) if allow_buffer_view and self.can_view() else self.e(MetaOps.CONTIGUOUS)
lazy.py                       :    28:          if (sti := self.st.invert(self.base.shape)) is not None: self.base.contiguous_child = ref(ret), sti
lazy.py                       :    28:          return ret
lazy.py                       :    28:        self.base.forced_realize = True
lazy.py                       :    28:        return self
lazy.py                       :    28:      def cast(self, dtype:DType, bitcast:bool=False, allow_buffer_view=True):
lazy.py                       :    28:        if self.dtype == dtype: return self
lazy.py                       :    28:        if self.device.startswith("DISK") and not bitcast: raise RuntimeError("attempted to cast disk buffer (bitcast only)")
lazy.py                       :    28:        if self.is_unrealized_unmasked_const() and not bitcast:
lazy.py                       :    28:          return create_lazybuffer(self.device, self.st, dtype, MetaOps.CONST, dtypes.as_const(self.base.arg, dtype))
lazy.py                       :    28:        new_shape = self.shape
lazy.py                       :    28:        if bitcast and self.dtype.itemsize != dtype.itemsize:
lazy.py                       :    28:          if not self.device.startswith("DISK"): raise RuntimeError("shape changing bitcast only supported on DISK right now")
lazy.py                       :    28:          if not all_int(new_shape): raise RuntimeError("shape changing bitcast with symbolic shape isn't supported yet")
lazy.py                       :    28:          # https://pytorch.org/docs/stable/generated/torch.Tensor.view.html
lazy.py                       :    28:          if not (new_shape[-1]*self.dtype.itemsize) % dtype.itemsize == 0: raise RuntimeError("unsupported size in bitcast")
lazy.py                       :    28:          new_shape = new_shape[:-1] + ((new_shape[-1]*self.dtype.itemsize) // dtype.itemsize,)
lazy.py                       :    28:        elif getenv("CAST_BEFORE_VIEW", 1) and dtype.itemsize <= self.dtype.itemsize and self != self.base:
lazy.py                       :    28:          # TODO: applying this makes gpt2 slower
lazy.py                       :    28:          return self.base.cast(dtype, bitcast)._view(self.st)
lazy.py                       :    28:        cast_op: Union[MetaOps, UnaryOps] = (MetaOps.VIEW if self.can_view() and allow_buffer_view else UnaryOps.BITCAST) if bitcast else UnaryOps.CAST
lazy.py                       :    28:        return create_lazybuffer(self.device, ShapeTracker.from_shape(new_shape), dtype, cast_op, dtype, (self,))
lazy.py                       :    28:      def is_unrealized_const(self): return self.base.realized is None and self.base.op is MetaOps.CONST and not isinstance(self.base.arg, Variable)
lazy.py                       :    28:      def is_unrealized_unmasked_const(self): return self.is_unrealized_const() and all(v.mask is None for v in self.st.views)
lazy.py                       :    28:      def _copy(self, device:str) -> LazyBuffer:
lazy.py                       :    28:        return create_lazybuffer(device, ShapeTracker.from_shape(self.shape), self.dtype, MetaOps.COPY, self.buffer.nbytes, (self,), enable_cache=False)
lazy.py                       :    28:      def copy_to_device(self, device:str, force: bool = False) -> LazyBuffer:
lazy.py                       :    28:        # no COPY
lazy.py                       :    28:        if self.device == device: return self
lazy.py                       :    28:        # double COPY = one COPY
lazy.py                       :    28:        if not force and self.st.contiguous and self.size == self.base.size and not self.base.realized and self.base.op is MetaOps.COPY:
lazy.py                       :    28:          return self.base.srcs[0].copy_to_device(device).reshape(self.st.shape)
lazy.py                       :    28:        # const doesn't have to be copied (issues with disk tensor)
lazy.py                       :    28:        if self.is_unrealized_const():
lazy.py                       :    28:          return LazyBuffer.metaop(MetaOps.CONST, tuple(), self.dtype, device, arg=self.base.arg)._view(self.st)
lazy.py                       :    28:        # if it's a shrink, do the shrink before the copy with CONTIGUOUS
lazy.py                       :    28:        if prod(self.st.shape) < prod(self.base.st.shape): return self.contiguous()._copy(device)
lazy.py                       :    28:        # copy the base and apply the shapetracker on the new device
lazy.py                       :    28:        return self.base._copy(device)._view(self.st)
lazy.py                       :    28:      def e(self, op:Union[MetaOps, UnaryOps, BinaryOps, TernaryOps], *in_srcs:LazyBuffer, arg:Optional[Any]=None) -> LazyBuffer:
lazy.py                       :    28:        srcs: List[LazyBuffer] = []
lazy.py                       :    28:        for s in (self,)+in_srcs:
lazy.py                       :    28:          if s == s.base and s.base.contiguous_child and (root:=s.base.contiguous_child[0]()) is not None:
lazy.py                       :    28:            srcs.append(root._view(s.base.contiguous_child[1]))
lazy.py                       :    28:          else:
lazy.py                       :    28:            srcs.append(s)
lazy.py                       :    28:        assert all_same(dts:=[x.dtype.scalar() for x in (srcs[1:] if op is TernaryOps.WHERE else srcs)]), f"all dtypes must match {dts} on {op}"
lazy.py                       :    28:        assert all_same([x.shape for x in srcs]), f"all shapes must be the same {[x.shape for x in srcs]}"
lazy.py                       :    28:        if op is TernaryOps.WHERE: assert srcs[0].dtype == dtypes.bool, "TernaryOps.WHERE must have the first arg be bool"
lazy.py                       :    28:        if op is UnaryOps.NEG: assert srcs[0].dtype != dtypes.bool, "UnaryOps.NEG does not accept dtype bool"
lazy.py                       :    28:        out_dtype = dtypes.bool if op in (BinaryOps.CMPLT, BinaryOps.CMPNE) else srcs[-1].dtype
lazy.py                       :    28:        # const folding
lazy.py                       :    28:        if op in python_alu and all(s.is_unrealized_unmasked_const() for s in srcs):
lazy.py                       :    28:          return self.cast(out_dtype).const(exec_alu(op, out_dtype, [s.base.arg for s in srcs]))
lazy.py                       :    28:        if op is UnaryOps.NEG and self.base.op is UnaryOps.NEG and self.base.realized is None: return self.base.srcs[0]
lazy.py                       :    28:        if op in BinaryOps:
lazy.py                       :    28:          x, y = self, in_srcs[0]
lazy.py                       :    28:          if op is BinaryOps.ADD:
lazy.py                       :    28:            if y.is_unrealized_unmasked_const() and y.base.arg == 0: return x
lazy.py                       :    28:            if x.is_unrealized_unmasked_const() and x.base.arg == 0: return y
lazy.py                       :    28:          if op is BinaryOps.MUL:
lazy.py                       :    28:            if x.is_unrealized_unmasked_const() and (val := x.base.arg) in (1, 0, -1):
lazy.py                       :    28:              return y if val == 1 else y.const(0) if val == 0 else y.e(UnaryOps.NEG)
lazy.py                       :    28:            if y.is_unrealized_unmasked_const() and (val := y.base.arg) in (1, 0, -1):
lazy.py                       :    28:              return x if val == 1 else x.const(0) if val == 0 else x.e(UnaryOps.NEG)
lazy.py                       :    28:        return create_lazybuffer(self.device, ShapeTracker.from_shape(self.shape), out_dtype, op, arg, tuple(srcs))
lazy.py                       :    28:      # *** reduce ops ***
lazy.py                       :    28:      def _reduce_op(self, op:ReduceOps, axis:Tuple[int, ...]) -> LazyBuffer:
lazy.py                       :    28:        assert all(0 <= x < len(self.shape) for x in axis), f"axis args {axis} out of range for shape {self.shape}"
lazy.py                       :    28:        axis = tuple(sorted([x for x in axis if self.shape[x] != 1]))
lazy.py                       :    28:        if len(axis) == 0: return self
lazy.py                       :    28:        return create_lazybuffer(self.device, ShapeTracker.from_shape(reduce_st(self.st, axis)), self.dtype, op, axis, (self,))
lazy.py                       :    28:      def r(self, op:ReduceOps, axis:Tuple[int, ...]) -> LazyBuffer:
lazy.py                       :    28:        new_shape = reduce_st(self.st, axis)
lazy.py                       :    28:        # TODO: this logic should move to the scheduler
lazy.py                       :    28:        if 0 in self.shape and 0 not in new_shape: return self.const({ReduceOps.SUM: 0.0, ReduceOps.MAX: dtypes.min(self.dtype)}[op], new_shape)
lazy.py                       :    28:        # const folding
lazy.py                       :    28:        # TODO: fold this for symbolic?
lazy.py                       :    28:        if self.is_unrealized_unmasked_const() and all_int(self.shape):
lazy.py                       :    28:          return self.const(self.base.arg * {ReduceOps.SUM: prod(self.shape[i] for i in axis), ReduceOps.MAX: 1}[op], new_shape)
lazy.py                       :    28:        # TODO: can we split symbolic shape if the reduce axis is not symbolic?
lazy.py                       :    28:        if not getenv("SPLIT_REDUCEOP", 1) or not all_int(self.shape) or (0 in self.shape) or \
lazy.py                       :    28:          prod(self.shape) // prod(new_shape) < getenv("REDUCEOP_SPLIT_THRESHOLD", 32768):
lazy.py                       :    28:          return self._reduce_op(op, axis)
lazy.py                       :    28:        # if there are few globals, make some reduces into globals by splitting into two kernels
lazy.py                       :    28:        # cap output buffer to 2**22: heuristic number of global outputs to achieve max occupancy with enough locals+upcasts for gemm
lazy.py                       :    28:        #   ~2**10 should be enough if GROUP is used
lazy.py                       :    28:        # 256 split maximum should be "negligible reduce" for low prod(new_shape), 8 split minimum.
lazy.py                       :    28:        # split is moved to the end to provide maximum locality for the second phase reduce.
lazy.py                       :    28:        self_real_strides = self.st.real_strides(ignore_valid=True)
lazy.py                       :    28:        split_candidates = [(i, x) for i in axis for x in range(min(256,2**getenv("REDUCEOP_SPLIT_SIZE",22)//prod(new_shape)),8-1,-1)

codegen/lowerer.py            :    15:  render_ops: Any = { NumNode: lambda self, ops, ctx: UOp.const(dtypes.bigint, self.b),
codegen/lowerer.py            :    15:                      MulNode: lambda self, ops, ctx: self.a.render(ops, ctx)*variable_to_uop(self.b, ctx),
codegen/lowerer.py            :    15:                      DivNode: lambda self, ops, ctx: self.a.render(ops, ctx)//variable_to_uop(self.b, ctx),
codegen/lowerer.py            :    15:                      ModNode: lambda self, ops, ctx: self.a.render(ops, ctx)%variable_to_uop(self.b, ctx),
codegen/lowerer.py            :    15:                      LtNode: lambda self, ops, ctx: self.a.render(ops, ctx).lt(variable_to_uop(self.b, ctx)),
codegen/lowerer.py            :    15:    Variable: lambda self,ops,ctx: ctx[self] if ctx is not None and self in ctx else UOp(UOps.DEFINE_VAR, dtypes.int32, (), self),
codegen/lowerer.py            :    15:    SumNode: lambda self,ops,ctx: functools.reduce(lambda a,b: a+b.render(ops, ctx), self.nodes[1:], self.nodes[0].render(ops,ctx)),
codegen/lowerer.py            :    15:    AndNode: lambda self,ops,ctx: functools.reduce(lambda a,b: a*b.render(ops, ctx), self.nodes[1:], self.nodes[0].render(ops,ctx)) }
codegen/lowerer.py            :    24:  if getenv("UOP_IS_SYMBOLIC"):

codegen/kernel.py             :    22:    class OptOps(Enum):
codegen/kernel.py             :    23:      TC = auto(); UPCAST = auto(); UPCASTMID = auto(); UNROLL = auto(); LOCAL = auto() # noqa: E702
codegen/kernel.py             :    24:      GROUP = auto(); GROUPTOP = auto(); NOLOCALS = auto(); PADTO = auto(); MERGE = auto(); SWAP = auto() # noqa: E702

codegen/kernel.py             :    33:    @dataclass(frozen=True, order=True)
codegen/kernel.py             :    33:    class Opt:
codegen/kernel.py             :    34:      op: OptOps
codegen/kernel.py             :    35:      axis: Optional[int] = None
codegen/kernel.py             :    36:      amt: Optional[int] = None

codegen/kernel.py             :    45:    @dataclass
codegen/kernel.py             :    45:    class TensorCoreOptions:
codegen/kernel.py             :    46:      axes: Tuple[int, ...] # the location of the original N and M axes if still in the shape
codegen/kernel.py             :    47:      axes_exist: Tuple[bool, ...] # true if the original N and M axes are still in the shape
codegen/kernel.py             :    48:      axis_pads: Tuple[Tuple[int, int], ...]

codegen/kernel.py             :    56:    class Kernel:
codegen/kernel.py             :   638:      kernel_cnt: Final[DefaultDict[str, int]] = defaultdict(int)

engine/graph.py               :    11:  with contextlib.suppress(ImportError): import networkx as nx
engine/graph.py               :    15:  if DEBUG >= 2:
engine/graph.py               :    27:  G:Any = None
engine/graph.py               :    34:  counts: DefaultDict[type, int] = defaultdict(int)
engine/graph.py               :    47:  top_colors = {MetaOps: '#FFFFa0', UnaryOps: "#c0c0c0", ReduceOps: "#FFA0A0", BinaryOps: "#c0c0c0",
engine/graph.py               :    47:                TernaryOps: "#c0c0c0", BufferOps: '#a0a0ff'}
engine/graph.py               :    77:  graph_uops_cnt = 0
engine/schedule.py            :    16:  sys.setrecursionlimit(10000)
engine/schedule.py            :    19:  logops = open(getenv("LOGOPS", ""), "a") if getenv("LOGOPS", "") else None

engine/schedule.py            :    24:    @dataclass(frozen=True)
engine/schedule.py            :    24:    class ScheduleItem:
engine/schedule.py            :    25:      ast: LazyOp
engine/schedule.py            :    26:      bufs: Tuple[Buffer, ...]
engine/schedule.py            :    27:      metadata: Optional[List[Metadata]] = None

engine/schedule.py            :   136:      children:DefaultDict[LazyBuffer, Dict[LazyBuffer, None]], assign_targets:Dict[LazyBuffer, LazyBuffer], scheduled=False):
engine/schedule.py            :   136:    """recursively search the entire graph for all LazyBuffers, insert realizes after expands"""
engine/schedule.py            :   136:    if buf in allbufs or buf.base.realized is not None: return
engine/schedule.py            :   136:    if GRAPH: log_lazybuffer(buf, scheduled)
engine/schedule.py            :   136:    # check if we need to realize views
engine/schedule.py            :   136:    if buf is not buf.base:
engine/schedule.py            :   136:      # fuse some pads
engine/schedule.py            :   136:      if len(buf.st.views) == 1 and buf.st.views[-1].mask is not None and all_int(buf.base.st.shape) and \
engine/schedule.py            :   136:          prod(buf.base.st.shape) >= prod([y-x for x,y in buf.st.views[-1].mask]):
engine/schedule.py            :   136:        simple_pads[buf.base] = None
engine/schedule.py            :   136:      # realize all expands
engine/schedule.py            :   136:      elif prod(buf.base.st.shape) < prod(buf.st.shape):
engine/schedule.py            :   136:        # this was causing "test_lil_model" to fail
engine/schedule.py            :   136:        if buf.base.op is UnaryOps.CAST and isinstance(buf.base.srcs[0].dtype, ImageDType) and isinstance(buf.base.arg, ImageDType):
engine/schedule.py            :   136:          simple_pads[buf.base] = None # don't realize image to image casts. this is part of a larger problem
engine/schedule.py            :   136:        elif not FUSE_AS_ONE_KERNEL: realizes[buf.base] = None
engine/schedule.py            :   136:      # check all other pads for safe fusion
engine/schedule.py            :   136:      elif any(v.mask is not None for v in buf.st.views): simple_pads[buf.base] = None
engine/schedule.py            :   136:      return _recurse_lb(buf.base, realizes, allbufs, simple_pads, children, assign_targets)
engine/schedule.py            :   136:    allbufs[buf] = None
engine/schedule.py            :   136:    if buf.forced_realize or buf.op in MetaOps: realizes[buf] = None
engine/schedule.py            :   136:    if buf.op is MetaOps.ASSIGN:
engine/schedule.py            :   136:      assert buf.srcs[1].base is buf.srcs[1], f"assign must be to base {buf.srcs[1]}"
engine/schedule.py            :   136:      assert buf.srcs[1].realized is not None, f"assign must be already realized to schedule {buf.srcs[1]}"
engine/schedule.py            :   136:      assign_targets[buf.srcs[1]] = buf
engine/schedule.py            :   136:    if buf.op is MetaOps.COPY:
engine/schedule.py            :   136:      assert buf.srcs[0].st.contiguous and buf.srcs[0].size == buf.srcs[0].base.size, "can only copy contig"
engine/schedule.py            :   136:      realizes[buf.srcs[0].base] = None
engine/schedule.py            :   136:    if buf.op is MetaOps.VIEW: realizes[buf.srcs[0].base] = None
engine/schedule.py            :   136:    for x in buf.srcs:
engine/schedule.py            :   136:      if x.base.realized is None: children[x.base][buf] = None
engine/schedule.py            :   136:      _recurse_lb(x, realizes, allbufs, simple_pads, children, assign_targets)
engine/schedule.py            :   136:  def _is_padding_okay(buf:LazyBuffer, realizes:Dict[LazyBuffer, None]) -> bool:
engine/schedule.py            :   136:    if buf in realizes or buf.realized is not None: return True
engine/schedule.py            :   136:    # NOTE: this broke to_image_idx and coder with JIT
engine/schedule.py            :   136:    if buf.op in UNSAFE_PAD_OPS: return False
engine/schedule.py            :   136:    return all(_is_padding_okay(x.base, realizes) for x in buf.srcs)
engine/schedule.py            :   136:  def _recursive_group(tr:LazyBuffer, st:ShapeTracker, r:LazyBuffer, children:DefaultDict[LazyBuffer, Dict[LazyBuffer, None]],
engine/schedule.py            :   309:  SCHEDULES: List = []
engine/realize.py             :    15:  logkerns, logkerns_level = open(getenv("LOGKERNS", ""), "a") if getenv("LOGKERNS", "") else None, getenv("LOGKERNS_LEVEL", 1)
engine/realize.py             :   147:  method_cache: Dict[Tuple[str, LazyOp, int, bool], CompiledRunner] = {}

engine/realize.py             :   165:    @dataclass(frozen=True)
engine/realize.py             :   165:    class ExecItem:
engine/realize.py             :   166:      prg: Runner
engine/realize.py             :   167:      bufs: List[Optional[Buffer]]
engine/realize.py             :   168:      metadata: Optional[List[Metadata]] = None

engine/realize.py             :   214:  capturing: List = []  # put classes with an add method in here

tensor.py                     :    92:    class Tensor:
tensor.py                     :    93:      """
tensor.py                     :   103:      __slots__ = "lazydata", "requires_grad", "grad", "_ctx"
tensor.py                     :   104:      __deletable__ = ('_ctx',)
tensor.py                     :   105:      training: ClassVar[bool] = False
tensor.py                     :   106:      no_grad: ClassVar[bool] = False
tensor.py                     :   109:                   device:Optional[Union[str, tuple, list]]=None, dtype:Optional[DType]=None, requires_grad:Optional[bool]=None):
tensor.py                     :   109:        assert dtype is None or isinstance(dtype, DType), f"invalid dtype {dtype}"
tensor.py                     :   109:        device = tuple(Device.canonicalize(x) for x in device) if isinstance(device, (tuple, list)) else Device.canonicalize(device)
tensor.py                     :   109:        # tensors can have gradients if you have called .backward
tensor.py                     :   109:        self.grad: Optional[Tensor] = None
tensor.py                     :   109:        # NOTE: this can be in three states. False and None: no gradient, True: gradient
tensor.py                     :   109:        # None (the default) will be updated to True if it's put in an optimizer
tensor.py                     :   109:        self.requires_grad: Optional[bool] = requires_grad
tensor.py                     :   109:        # internal variable used for autograd graph construction
tensor.py                     :   109:        self._ctx: Optional[Function] = None
tensor.py                     :   109:        # create a LazyBuffer from the different types of inputs
tensor.py                     :   109:        if isinstance(data, LazyBuffer): assert dtype is None or dtype == data.dtype, "dtype doesn't match, and casting isn't supported"
tensor.py                     :   109:        elif isinstance(data, get_args(ConstType)): data = _metaop(MetaOps.CONST, tuple(), dtype or dtypes.from_py(data), device, data)
tensor.py                     :   109:        elif isinstance(data, Variable): data = _metaop(MetaOps.CONST, tuple(), dtype or dtypes.from_py(data.unbind()[1]), device, data)
tensor.py                     :   109:        elif isinstance(data, bytes): data = _frompy(data, dtypes.uint8 if dtype is None else dtype)
tensor.py                     :   109:        elif isinstance(data, (list, tuple)):
tensor.py                     :   109:          if dtype is None:
tensor.py                     :   109:            if (d := fully_flatten(data)) and all(isinstance(s, bool) for s in d): dtype = dtypes.bool
tensor.py                     :   109:            else: dtype = dtypes.default_int if d and all_int(d) else dtypes.default_float
tensor.py                     :   109:          if dtype == dtypes.bfloat16: data = Tensor(_fromnp(np.array(data, np.float32)), device=device).cast(dtypes.bfloat16).lazydata
tensor.py                     :   109:          else: data = _fromnp(np.array(data).astype(_to_np_dtype(dtype)))
tensor.py                     :   109:        elif data is None: data = _metaop(MetaOps.EMPTY, (0,), dtype or dtypes.default_float, device)
tensor.py                     :   109:        elif isinstance(data, np.ndarray):
tensor.py                     :   109:          if data.shape == (): data = _metaop(MetaOps.CONST, tuple(), dtype or _from_np_dtype(data.dtype), device, data.item())
tensor.py                     :   109:          else: data = _fromnp(data.astype(npdtype) if dtype is not None and (npdtype:=_to_np_dtype(dtype)) is not None else data)
tensor.py                     :   109:        # by this point, it has to be a LazyBuffer
tensor.py                     :   109:        if not isinstance(data, (LazyBuffer, MultiLazyBuffer)):
tensor.py                     :   109:          raise RuntimeError(f"can't create Tensor from {data!r} with type {type(data)}")
tensor.py                     :   109:        # data is a LazyBuffer, but it might be on the wrong device
tensor.py                     :   109:        if isinstance(device, tuple):
tensor.py                     :   109:          # if device is a tuple, we should have/construct a MultiLazyBuffer
tensor.py                     :   109:          if isinstance(data, MultiLazyBuffer):
tensor.py                     :   109:            assert data.device == device, f"MultiLazyBuffer device mismatch, {data.device} != {device}"
tensor.py                     :   109:            self.lazydata: Union[LazyBuffer, MultiLazyBuffer] = data
tensor.py                     :   109:          else:
tensor.py                     :   109:            self.lazydata = MultiLazyBuffer.from_sharded(data, device, None)
tensor.py                     :   109:        else:
tensor.py                     :   109:          self.lazydata = data if data.device == device else data.copy_to_device(device)
tensor.py                     :   109:      class train(ContextDecorator):
tensor.py                     :   109:        def __init__(self, mode:bool = True): self.mode = mode
tensor.py                     :   109:        def __enter__(self): self.prev, Tensor.training = Tensor.training, self.mode
tensor.py                     :   109:        def __exit__(self, exc_type, exc_value, traceback): Tensor.training = self.prev
tensor.py                     :   109:      class inference_mode(ContextDecorator):
tensor.py                     :   109:        def __init__(self, mode:bool = True): self.mode = mode
tensor.py                     :   109:        def __enter__(self): self.prev, Tensor.no_grad = Tensor.no_grad, self.mode
tensor.py                     :   109:        def __exit__(self, exc_type, exc_value, traceback): Tensor.no_grad = self.prev
tensor.py                     :   109:      def __repr__(self):
tensor.py                     :   109:        return f"<Tensor {self.lazydata!r} on {self.device} with grad {(self.grad.lazydata if self.grad is not None else None)!r}>"
tensor.py                     :   109:      # Python has a non moving GC, so this should be okay
tensor.py                     :   109:      def __hash__(self): return id(self)
tensor.py                     :   109:      def __bool__(self): raise TypeError("__bool__ on Tensor is not defined")
tensor.py                     :   109:      def __len__(self):
tensor.py                     :   109:        if not self.shape: raise TypeError("len() of a 0-d tensor")
tensor.py                     :   109:        return self.shape[0]
tensor.py                     :   109:      @property
tensor.py                     :   109:      def device(self) -> Union[str, Tuple[str, ...]]: return self.lazydata.device
tensor.py                     :   109:      @property
tensor.py                     :   109:      def shape(self) -> Tuple[sint, ...]: return self.lazydata.shape
tensor.py                     :   109:      @property
tensor.py                     :   109:      def dtype(self) -> DType: return self.lazydata.dtype
tensor.py                     :   109:      # ***** data handlers ****
tensor.py                     :   109:      def schedule_with_vars(self, *lst:Tensor, seen:Optional[Set[LazyBuffer]]=None) -> Tuple[List[ScheduleItem], Dict[Variable, int]]:
tensor.py                     :   109:        """Creates the schedule needed to realize these Tensor(s), with Variables."""
tensor.py                     :   109:        if getenv("FUZZ_SCHEDULE"):
tensor.py                     :   109:          from test.external.fuzz_schedule import fuzz_schedule
tensor.py                     :   109:          fuzz_schedule(flatten([x.lazydata.lbs for x in (self,)+lst]))
tensor.py                     :   109:        schedule, var_vals = create_schedule_with_vars(flatten([x.lazydata.lbs for x in (self,)+lst]), seen)
tensor.py                     :   109:        return memory_planner(schedule), var_vals
tensor.py                     :   109:      def schedule(self, *lst:Tensor, seen:Optional[Set[LazyBuffer]]=None) -> List[ScheduleItem]:
tensor.py                     :   109:        """Creates the schedule needed to realize these Tensor(s)."""
tensor.py                     :   109:        schedule, var_vals = self.schedule_with_vars(*lst, seen=seen)
tensor.py                     :   109:        assert len(var_vals) == 0
tensor.py                     :   109:        return schedule
tensor.py                     :   109:      def realize(self, *lst:Tensor, do_update_stats=True) -> Tensor:
tensor.py                     :   109:        """Triggers the computation needed to create these Tensor(s)."""
tensor.py                     :   109:        run_schedule(*self.schedule_with_vars(*lst), do_update_stats=do_update_stats)
tensor.py                     :   109:        return self
tensor.py                     :   109:      def replace(self, x:Tensor) -> Tensor:
tensor.py                     :   109:        """

tensor.py                     :    92:    class Tensor:
tensor.py                     :   371:      _seed: int = int(time.time())
tensor.py                     :   372:      _rng_counter: Optional[Tensor] = None

tensor.py                     :  3123:  for device in Device._devices: setattr(Tensor, f"{device.lower()}", functools.partialmethod(Tensor.to, device))
tensor.py                     :  3125:  if IMAGE:
tensor.py                     :  3166:  if TRACEMETA >= 1:
tensor.py                     :  3167:    for name, fn in inspect.getmembers(Tensor, inspect.isfunction):
tensor.py                     :  3168:      if name in ["__class__", "__init__", "__repr__", "backward", "sequential"]: continue
tensor.py                     :  3169:      setattr(Tensor, name, functools.wraps(fn)(_metadata_wrapper(fn)))

tensor.py                     :  3138:    def _metadata_wrapper(fn):
tensor.py                     :  3164:      return _wrapper

nn/optim.py                   :     7:    class Optimizer:
nn/optim.py                   :     8:      """

nn/optim.py                   :    45:    class OptimizerGroup(Optimizer):
nn/optim.py                   :    46:      """

nn/optim.py                   :    67:    class LARS(Optimizer):
nn/optim.py                   :    68:      """

nn/optim.py                   :   119:    class LAMB(Optimizer):
nn/optim.py                   :   120:      """

nn/state.py                   :     9:  safe_dtypes = {"BOOL":dtypes.bool, "I8":dtypes.int8, "U8":dtypes.uint8, "I16":dtypes.int16, "U16":dtypes.uint16, "I32":dtypes.int, "U32":dtypes.uint,
nn/state.py                   :     9:                 "I64":dtypes.int64, "U64":dtypes.uint64, "F16":dtypes.float16, "BF16":dtypes.bfloat16, "F32":dtypes.float32, "F64":dtypes.float64}
nn/state.py                   :    11:  inverse_safe_dtypes = {v:k for k,v in safe_dtypes.items()}

nn/__init__.py                :     7:    class BatchNorm:
nn/__init__.py                :     8:      """

nn/__init__.py                :    62:  BatchNorm2d = BatchNorm3d = BatchNorm

nn/__init__.py                :    82:    class Conv2d:
nn/__init__.py                :    83:      """

nn/__init__.py                :   126:    class ConvTranspose2d(Conv2d):
nn/__init__.py                :   127:      """

nn/__init__.py                :   152:    class Linear:
nn/__init__.py                :   153:      """

nn/__init__.py                :   176:    class GroupNorm:
nn/__init__.py                :   177:      """

nn/__init__.py                :   207:    class InstanceNorm:
nn/__init__.py                :   208:      """

nn/__init__.py                :   234:    class LayerNorm:
nn/__init__.py                :   235:      """

nn/__init__.py                :   262:    class LayerNorm2d(LayerNorm):
nn/__init__.py                :   263:      """

nn/__init__.py                :   280:    class RMSNorm:
nn/__init__.py                :   281:      """

nn/__init__.py                :   302:    class Embedding:
nn/__init__.py                :   303:      """

engine/jit.py                 :   108:  ReturnType = TypeVar('ReturnType')
